{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d94223cb-3d96-4aed-9628-98f5a9d5e3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk import FreqDist, NaiveBayesClassifier, classify\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec301ad6-1f6a-4266-adf8-2306e75f1dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\srudloff\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\srudloff\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\srudloff\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\srudloff\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\srudloff\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\srudloff\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\twitter_samples.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"twitter_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6a7d68-a138-4cd8-ad38-c03e43892a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lemmatize_sentence(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in pos_tag(tokens):\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = \"n\"\n",
    "        elif tag.startswith(\"VB\"):\n",
    "            pos = \"v\"\n",
    "        else:\n",
    "            pos = \"a\"\n",
    "        lemmatized_sentence.append(lemmatizer.lemmatize(word, pos))\n",
    "    return lemmatized_sentence\n",
    "\n",
    "\n",
    "def remove_noise(tweet_tokens, stop_words=()):\n",
    "    cleaned_tokens = []\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        token = re.sub(\n",
    "            \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|\"\n",
    "            \"(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\n",
    "            \"\",\n",
    "            token,\n",
    "        )\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\", \"\", token)\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = \"n\"\n",
    "        elif tag.startswith(\"VB\"):\n",
    "            pos = \"v\"\n",
    "        else:\n",
    "            pos = \"a\"\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if (\n",
    "            len(token) > 0\n",
    "            and token not in string.punctuation\n",
    "            and token.lower() not in stop_words\n",
    "        ):\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "695f1fb3-1736-4a30-9016-e0c6f31c034f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_words(cleaned_tokens_list):\n",
    "    for tokens in cleaned_tokens_list:\n",
    "        for token in tokens:\n",
    "            yield token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee6ad2f6-d6ab-4689-aba2-17ae48d43fff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tweets_for_model(cleaned_tokens_list):\n",
    "    for tweet_tokens in cleaned_tokens_list:\n",
    "        yield dict([token, True] for token in tweet_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a06243a-0d56-4309-a117-c567b095d734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positive_tweets = twitter_samples.strings(\"positive_tweets.json\")\n",
    "negative_tweets = twitter_samples.strings(\"negative_tweets.json\")\n",
    "text = twitter_samples.strings(\"tweets.20150430-223406.json\")\n",
    "tweet_tokens = twitter_samples.tokenized(\"positive_tweets.json\")[0]\n",
    "tweet_tokens = twitter_samples.tokenized(\"positive_tweets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec6aa3cc-1529-43eb-840c-0eb38bc27443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "positive_tweet_tokens = twitter_samples.tokenized(\"positive_tweets.json\")\n",
    "negative_tweet_tokens = twitter_samples.tokenized(\"negative_tweets.json\")\n",
    "\n",
    "positive_cleaned_tokens_list = []\n",
    "negative_cleaned_tokens_list = []\n",
    "\n",
    "for tokens in positive_tweet_tokens:\n",
    "    positive_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "for tokens in negative_tweet_tokens:\n",
    "    negative_cleaned_tokens_list.append(remove_noise(tokens, stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dc6c3be-8c9e-4c2e-a312-2df7bf66cfca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_pos_words = get_all_words(positive_cleaned_tokens_list)\n",
    "freq_dist_pos = FreqDist(all_pos_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34023b73-9b80-4c87-b853-7d47bc72c99d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positive_tokens_for_model = get_tweets_for_model(positive_cleaned_tokens_list)\n",
    "negative_tokens_for_model = get_tweets_for_model(negative_cleaned_tokens_list)\n",
    "\n",
    "positive_dataset = [\n",
    "    (tweet_dict, \"Positive\") for tweet_dict in positive_tokens_for_model\n",
    "]\n",
    "\n",
    "negative_dataset = [\n",
    "    (tweet_dict, \"Negative\") for tweet_dict in negative_tokens_for_model\n",
    "]\n",
    "\n",
    "dataset = positive_dataset + negative_dataset\n",
    "\n",
    "random.shuffle(dataset)\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(dataset)\n",
    "with open('naive_bayes_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f635344b-0004-4125-bcd5-537d384643d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Analysis(t):\n",
    "    custom_tokens = remove_noise(word_tokenize(t))\n",
    "    return classifier.classify(dict([token, True] for token in custom_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22884e77-40aa-4830-9fbc-d2c8fa0a4faa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Analysis(\"Hey guys i just got back from vacation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b7a155e-a521-491a-a2ad-d9c3917e3a76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Analysis(\"I just got back from the hospital.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7c8152-dfd2-46b2-a193-4e0a45a89d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35a3c1c0-208b-46c8-9f8f-1e8494f57857",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey guys i just got back from vacation!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I just got back from the hospital. dad is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I just got back from the hospital. the baby is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When people ask me stupid questions, it is my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m not saying I hate you, what I'm saying is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Silence is golden. Duct tape is silver.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I am busy right now, can I ignore you some oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Find your patience before\" I lose mine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It's okay if you don’t like me. Not everyone h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Do you think God gets stoned? I think so… look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Light travels faster than sound. This is why s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>If you find me offensive. Then I suggest you q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sarcasm is the body’s natural defense against ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0             Hey guys i just got back from vacation!\n",
       "1   I just got back from the hospital. dad is not ...\n",
       "2   I just got back from the hospital. the baby is...\n",
       "3   When people ask me stupid questions, it is my ...\n",
       "4   I’m not saying I hate you, what I'm saying is ...\n",
       "5             Silence is golden. Duct tape is silver.\n",
       "6   I am busy right now, can I ignore you some oth...\n",
       "7             Find your patience before\" I lose mine.\n",
       "8   It's okay if you don’t like me. Not everyone h...\n",
       "9   Do you think God gets stoned? I think so… look...\n",
       "10  Light travels faster than sound. This is why s...\n",
       "11  If you find me offensive. Then I suggest you q...\n",
       "12  Sarcasm is the body’s natural defense against ..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = [{'text':i} for i in \"\"\"\n",
    "Hey guys i just got back from vacation!\n",
    "I just got back from the hospital. dad is not doing well.\n",
    "I just got back from the hospital. the baby is so cute.\n",
    "When people ask me stupid questions, it is my legal obligation to give a sarcastic remark.\n",
    "I’m not saying I hate you, what I'm saying is that you are literally the Monday of my life.\n",
    "Silence is golden. Duct tape is silver.\n",
    "I am busy right now, can I ignore you some other time?\n",
    "Find your patience before\" I lose mine.\n",
    "It's okay if you don’t like me. Not everyone has good taste.\n",
    "Do you think God gets stoned? I think so… look at the platypus.\n",
    "Light travels faster than sound. This is why some people appear bright until they speak.\n",
    "If you find me offensive. Then I suggest you quit finding me.\n",
    "Sarcasm is the body’s natural defense against stupidity.\"\"\".strip().splitlines()]\n",
    "lines = pd.DataFrame(lines)\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "450b0a00-0035-461c-af70-89df4a09e003",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey guys i just got back from vacation!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I just got back from the hospital. dad is not ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I just got back from the hospital. the baby is...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When people ask me stupid questions, it is my ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m not saying I hate you, what I'm saying is ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Silence is golden. Duct tape is silver.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I am busy right now, can I ignore you some oth...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Find your patience before\" I lose mine.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It's okay if you don’t like me. Not everyone h...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Do you think God gets stoned? I think so… look...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Light travels faster than sound. This is why s...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>If you find me offensive. Then I suggest you q...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sarcasm is the body’s natural defense against ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment\n",
       "0             Hey guys i just got back from vacation!  Positive\n",
       "1   I just got back from the hospital. dad is not ...  Negative\n",
       "2   I just got back from the hospital. the baby is...  Negative\n",
       "3   When people ask me stupid questions, it is my ...  Positive\n",
       "4   I’m not saying I hate you, what I'm saying is ...  Negative\n",
       "5             Silence is golden. Duct tape is silver.  Negative\n",
       "6   I am busy right now, can I ignore you some oth...  Negative\n",
       "7             Find your patience before\" I lose mine.  Negative\n",
       "8   It's okay if you don’t like me. Not everyone h...  Positive\n",
       "9   Do you think God gets stoned? I think so… look...  Positive\n",
       "10  Light travels faster than sound. This is why s...  Positive\n",
       "11  If you find me offensive. Then I suggest you q...  Negative\n",
       "12  Sarcasm is the body’s natural defense against ...  Positive"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def do_analysis(row):\n",
    "    sentiment = Analysis(row['text'])\n",
    "    row['sentiment'] = sentiment\n",
    "    return row\n",
    "\n",
    "lines = lines.apply(do_analysis, axis=1)\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60e08c6c-caaf-4eb7-9cc8-6c0ab6478375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lines.to_csv('nktl_method.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc71707f-8bec-4e94-9ed1-bb8bc481d651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "scenes_data": {
   "active_scene": "Default Scene",
   "init_scene": "",
   "scenes": [
    "Default Scene"
   ]
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
