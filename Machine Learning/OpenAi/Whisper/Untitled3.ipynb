{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1e46e4d-da30-497c-a372-bc159dbbd722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ID: 3, Device Name: HD-Audio Generic: ALC257 Analog (hw:1,0), Input Channels: 2\n",
      "Device ID: 4, Device Name: acp: - (hw:2,0), Input Channels: 2\n",
      "Device ID: 5, Device Name: ThinkPad USB-C Dock Gen2 USB Au: Audio (hw:3,0), Input Channels: 1\n",
      "Device ID: 6, Device Name: P2418HZm: USB Audio (hw:5,0), Input Channels: 2\n",
      "Device ID: 8, Device Name: pulse, Input Channels: 32\n",
      "Device ID: 9, Device Name: default, Input Channels: 32\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "def list_audio_input_devices():\n",
    "    p = pyaudio.PyAudio()\n",
    "    device_count = p.get_device_count()\n",
    "    for i in range(device_count):\n",
    "        device_info = p.get_device_info_by_index(i)\n",
    "        device_id = device_info['index']\n",
    "        device_name = device_info['name']\n",
    "        max_input_channels = device_info['maxInputChannels']\n",
    "        # Display the device ID and name only if it has input channels (microphone)\n",
    "        if max_input_channels > 0:\n",
    "            print(f\"Device ID: {device_id}, Device Name: {device_name}, Input Channels: {max_input_channels}\")\n",
    "    p.terminate()\n",
    "\n",
    "# Call the function to list the audio input devices (microphones)\n",
    "list_audio_input_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ead5cd-738c-456b-9edb-2e0f445f4b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Recording started. Press Enter to stop recording...\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_pulse.c:758:(pulse_prepare) PulseAudio: Unable to create stream: Timeout\n",
      "\n",
      "Expression 'alsa_snd_pcm_prepare( stream->capture.pcm )' failed in 'src/hostapi/alsa/pa_linux_alsa.c', line: 2932\n",
      "Expression 'AlsaStart( stream, 0 )' failed in 'src/hostapi/alsa/pa_linux_alsa.c', line: 4244\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "import threading\n",
    "import openai\n",
    "import keyring\n",
    "import wave\n",
    "import tempfile\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Define audio recording parameters\n",
    "input_default_samplerate = 44100  # Sample rate\n",
    "device_id = 9  # Change this to the appropriate audio device ID\n",
    "recording_duration = 5  # Duration of recording for noise baseline in seconds\n",
    "chunk_duration = 3  # Duration of each chunk in seconds\n",
    "chunk_samples = int(input_default_samplerate * chunk_duration)  # Number of samples in each chunk\n",
    "threshold_multiplier = 1.5  # Multiplier for noise threshold\n",
    "gain_factor = 2.0  # Amplify the audio by a factor of 2\n",
    "\n",
    "# Define a function to save the numpy array as a WAV file in memory\n",
    "def save_wav_in_memory(audio_data):\n",
    "    byte_io = io.BytesIO()\n",
    "    with wave.open(byte_io, 'wb') as wav_file:\n",
    "        wav_file.setnchannels(1)\n",
    "        wav_file.setsampwidth(2)\n",
    "        wav_file.setframerate(input_default_samplerate)\n",
    "        wav_file.writeframes(audio_data.astype(np.int16).tobytes())\n",
    "    byte_io.seek(0)\n",
    "    return byte_io.read()\n",
    "\n",
    "# Calculate root-mean-square (RMS) energy of a chunk\n",
    "def calculate_rms(chunk):\n",
    "    return np.sqrt(np.mean(np.square(chunk)))\n",
    "\n",
    "# Simple Voice Activity Detection (VAD)\n",
    "def is_voice_active(chunk, threshold):\n",
    "    rms = calculate_rms(chunk)\n",
    "    return rms, rms > threshold\n",
    "\n",
    "# Define a function for recording audio and transcribing chunks\n",
    "def record_and_transcribe(stop_event, threshold):\n",
    "    active_chunk = np.array([])\n",
    "    is_talking = False\n",
    "    recording_start = time.time()\n",
    "\n",
    "    def callback(in_data, frame_count, time_info, status):\n",
    "        nonlocal active_chunk, is_talking, recording_start\n",
    "        # Convert byte data to numpy array and flatten\n",
    "        chunk = np.frombuffer(in_data, dtype=np.float32).flatten()\n",
    "        # Apply gain factor\n",
    "        chunk = chunk * gain_factor\n",
    "        rms, voice_active = is_voice_active(chunk, threshold)\n",
    "        if voice_active:\n",
    "            if not is_talking:\n",
    "                is_talking = True\n",
    "                recording_start = time.time()\n",
    "                print(\"Started Talking\", rms, threshold)\n",
    "            else:\n",
    "                print(\"Is Talking\", rms, threshold, time.time() - recording_start)\n",
    "            # If active voice detected, append chunk to active_chunk\n",
    "            active_chunk = np.concatenate((active_chunk, chunk))\n",
    "        elif len(active_chunk) > 0:\n",
    "            print(\"Stopped Talking\", rms, threshold, time.time() - recording_start)\n",
    "            # Save and transcribe the active_chunk\n",
    "            audio_bytes = save_wav_in_memory(active_chunk)\n",
    "            datetime_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            temp_filename = f\"temp_audio_{datetime_str}.wav\"\n",
    "            with open(temp_filename, \"wb\") as f:\n",
    "                f.write(audio_bytes)\n",
    "            print('wav:', temp_filename)\n",
    "            file = open(temp_filename, \"rb\")\n",
    "            transcription = openai.Audio.transcribe(\"whisper-1\", file)\n",
    "            print(transcription)\n",
    "            active_chunk = np.array([])\n",
    "        return (in_data, pyaudio.paContinue)\n",
    "\n",
    "    # Initialize PyAudio\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(\n",
    "        format=pyaudio.paFloat32,\n",
    "        channels=1,\n",
    "        rate=input_default_samplerate,\n",
    "        input=True,\n",
    "        input_device_index=device_id,\n",
    "        stream_callback=callback,\n",
    "        frames_per_buffer=chunk_samples\n",
    "    )  \n",
    "    # Start the audio stream\n",
    "    stream.start_stream()\n",
    "\n",
    "    # Wait for stop_event to be set\n",
    "    stop_event.wait()\n",
    "\n",
    "    # Stop the audio stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    # Terminate PyAudio\n",
    "    p.terminate()\n",
    "\n",
    "    print(\"Recording and transcription complete.\")\n",
    "\n",
    "# OpenAI API key\n",
    "openai.api_key = keyring.get_password(\"system\", \"openai_key\")\n",
    "\n",
    "# Create an event to signal recording thread to stop\n",
    "stop_event = threading.Event()\n",
    "\n",
    "# Set an initial noise threshold\n",
    "noise_threshold = 0.008\n",
    "\n",
    "# Start recording and transcribing on a separate thread\n",
    "recording_thread = threading.Thread(target=record_and_transcribe, args=(stop_event, noise_threshold))\n",
    "recording_thread.start()\n",
    "\n",
    "# Prompt user to press Enter to stop recording\n",
    "input(\"Recording started. Press Enter to stop recording...\\n\")\n",
    "\n",
    "# Signal the recording thread to stop\n",
    "stop_event.set()\n",
    "recording_thread.join()\n",
    "\n",
    "print(\"Recording and transcription complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a88677-4acb-476d-9fd0-5e55275fa490",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "record_and_transcribe() missing 2 required positional arguments: 'stop_event' and 'threshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrecord_and_transcribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: record_and_transcribe() missing 2 required positional arguments: 'stop_event' and 'threshold'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb8fb7-1fc8-4542-8f1f-3559fdcf51cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
