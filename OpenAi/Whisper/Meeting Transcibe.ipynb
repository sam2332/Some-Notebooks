{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831233a2-6d33-4129-8b28-92d5deea79d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import wave\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import PySimpleGUI as sg\n",
    "import openai\n",
    "import keyring\n",
    "import threading\n",
    "from queue import Queue\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "\n",
    "openai.api_key =keyring.get_password(\"system\", \"openai_key\")\n",
    "\n",
    "\n",
    "# Define a function to save the numpy array as a WAV file in memory\n",
    "def save_wav_in_memory(audio_data: List[np.ndarray], sample_rate: int) -> bytes:\n",
    "    byte_io = io.BytesIO()\n",
    "    with wave.open(byte_io, 'wb') as wav_file:\n",
    "        wav_file.setnchannels(1)\n",
    "        wav_file.setsampwidth(2)\n",
    "        wav_file.setframerate(sample_rate)\n",
    "        for chunk in audio_data:\n",
    "            wav_file.writeframes(chunk.astype(np.int16).tobytes())\n",
    "    byte_io.seek(0)\n",
    "    return byte_io.read()\n",
    "\n",
    "# Define audio recording parameters\n",
    "fs = 44100  # Sample rate\n",
    "\n",
    "# Callback function for audio recording\n",
    "def audio_callback(indata, frames, time, status, q):\n",
    "    q.put(indata.copy())\n",
    "\n",
    "# Function for recording audio on a separate thread\n",
    "def record_audio(q, stop_event):\n",
    "    with sd.InputStream(callback=lambda *args: audio_callback(*args, q), samplerate=fs):\n",
    "        while not stop_event.is_set():\n",
    "            sd.sleep(100)  # Sleep for a short duration to reduce CPU usage\n",
    "\n",
    "\n",
    "# Define GUI layout\n",
    "layout = [\n",
    "    [sg.Button('Start Recording'), sg.Button('Stop Recording')],\n",
    "    [sg.Multiline(size=(60, 20), key='transcription')],\n",
    "]\n",
    "\n",
    "# Create GUI window\n",
    "window = sg.Window('Meeting Transcription', layout)\n",
    "\n",
    "# Create an event to signal recording thread to stop\n",
    "stop_event = threading.Event()\n",
    "\n",
    "# Create a queue to hold audio data chunks\n",
    "audio_queue = Queue()\n",
    "\n",
    "# Event loop\n",
    "recording_thread = None\n",
    "while True:\n",
    "    event, values = window.read()\n",
    "    if event == sg.WIN_CLOSED:\n",
    "        break\n",
    "    elif event == 'Start Recording':\n",
    "        # Start recording on a separate thread\n",
    "        stop_event.clear()\n",
    "        recording_thread = threading.Thread(target=record_audio, args=(audio_queue, stop_event))\n",
    "        recording_thread.start()\n",
    "    elif event == 'Stop Recording':\n",
    "        # Signal the recording thread to stop\n",
    "        stop_event.set()\n",
    "        if recording_thread is not None:\n",
    "            recording_thread.join()\n",
    "        # Collect audio data from the queue\n",
    "        audio_data = []\n",
    "        while not audio_queue.empty():\n",
    "            audio_data.append(audio_queue.get())\n",
    "        # Convert recording to audio file\n",
    "        audio_bytes = save_wav_in_memory(audio_data, fs)\n",
    "        current_timestamp = datetime.now()       \n",
    "        temp_audio_path = current_timestamp.strftime(\"temp_audio_%Y%m%d_%H%M%S.wav\")\n",
    "\n",
    "        # Save the audio to a temporary WAV file\n",
    "        with open(temp_audio_path, \"wb\") as f:\n",
    "            f.write(audio_bytes)\n",
    "\n",
    "        file = open(temp_audio_path, \"rb\")\n",
    "        transcription = openai.Audio.transcribe(\"whisper-1\", file)\n",
    "\n",
    "        print(transcription)\n",
    "        # Update GUI with transcribed text\n",
    "        window['transcription'].update(transcription['text'])\n",
    "\n",
    "# Close GUI window\n",
    "window.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1583557d-261c-40e0-8e65-4fdd51f36945",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Device ID: 0 / HD-Audio Generic: ALC257 Analog (hw:1,0) / Max Input Channels: 2\n",
      "Input Device ID: 0 / acp: - (hw:2,0) / Max Input Channels: 2\n",
      "Input Device ID: 0 / ThinkPad USB-C Dock Gen2 USB Au: Audio (hw:3,0) / Max Input Channels: 1\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "# Get the list of all devices\n",
    "devices = sd.query_devices()\n",
    "\n",
    "# Filter input devices\n",
    "input_devices = [device for device in devices if device['max_input_channels'] > 0]\n",
    "\n",
    "# Print input devices\n",
    "for idx, device in enumerate(input_devices):\n",
    "    print(f\"Input Device ID: {device['hostapi']} / {device['name']} / Max Input Channels: {device['max_input_channels']}\")\n",
    "\n",
    "# If "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f82f6b-d14a-44e6-9b35-c5e5b07935fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287bfe8-d128-4aa5-9859-c523eefda422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af880acc-700b-45de-ae5b-0195d20f5ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2cb0772-a163-40fa-a60c-a7c72f7a786a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8 (record_audio):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_489175/2010648215.py\", line 53, in record_audio\n",
      "  File \"<__array_function__ internals>\", line 200, in concatenate\n",
      "ValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 0 and the array at index 1 has size 2\n",
      "Exception in thread Thread-9 (record_audio):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_489175/2010648215.py\", line 53, in record_audio\n",
      "  File \"<__array_function__ internals>\", line 200, in concatenate\n",
      "ValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 0 and the array at index 1 has size 2\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import queue\n",
    "from datetime import datetime\n",
    "import openai\n",
    "import keyring\n",
    "import io\n",
    "import wave\n",
    "\n",
    "import PySimpleGUI as sg\n",
    "# Define audio recording parameters\n",
    "fs = 44100  # Sample rate\n",
    "recording_duration = 5  # Duration of recording for noise baseline in seconds\n",
    "chunk_duration = 0.5  # Duration of each chunk in seconds\n",
    "chunk_samples = int(fs * chunk_duration)  # Number of samples in each chunk\n",
    "threshold_multiplier = 1.5  # Multiplier for noise threshold\n",
    "\n",
    "# Define a function to save the numpy array as a WAV file in memory\n",
    "def save_wav_in_memory(audio_data, sample_rate):\n",
    "    byte_io = io.BytesIO()\n",
    "    with wave.open(byte_io, 'wb') as wav_file:\n",
    "        wav_file.setnchannels(1)\n",
    "        wav_file.setsampwidth(2)\n",
    "        wav_file.setframerate(sample_rate)\n",
    "        wav_file.writeframes(audio_data.astype(np.int16).tobytes())\n",
    "    byte_io.seek(0)\n",
    "    return byte_io.read()\n",
    "\n",
    "# Calculate root-mean-square (RMS) energy of a chunk\n",
    "def calculate_rms(chunk):\n",
    "    return np.sqrt(np.mean(np.square(chunk)))\n",
    "\n",
    "# Simple Voice Activity Detection (VAD)\n",
    "def is_voice_active(chunk, threshold):\n",
    "    return calculate_rms(chunk) > threshold\n",
    "\n",
    "# Define a function for recording audio on a separate thread\n",
    "def record_audio(audio_queue, stop_event, threshold):\n",
    "    buffer = np.array(([],[]))\n",
    "    active_chunk = np.array(([],[]))\n",
    "    with sd.InputStream(samplerate=fs) as stream:\n",
    "        while not stop_event.is_set():\n",
    "            chunk = stream.read(chunk_samples)[0]\n",
    "            if is_voice_active(chunk, threshold):\n",
    "                # If active voice detected, append chunk to active_chunk\n",
    "                active_chunk = np.concatenate((active_chunk, chunk))\n",
    "            elif len(active_chunk) > 0:\n",
    "                # If pause detected, put the active_chunk in queue for transcription\n",
    "                audio_queue.put(active_chunk)\n",
    "                active_chunk = np.array(([],[]))\n",
    "            # Append chunk to buffer for noise threshold calculation\n",
    "            buffer = np.concatenate((buffer, chunk))\n",
    "            if len(buffer) > fs * recording_duration:\n",
    "                # Calculate threshold based on RMS energy of recorded buffer\n",
    "                threshold = threshold_multiplier * calculate_rms(buffer)\n",
    "                buffer = np.array(([],[]))\n",
    "\n",
    "# OpenAI API key\n",
    "openai.api_key = keyring.get_password(\"system\", \"openai_key\")\n",
    "\n",
    "# Define GUI layout\n",
    "layout = [\n",
    "    [sg.Button('Start Recording'), sg.Button('Stop Recording')],\n",
    "    [sg.Multiline(size=(60, 20), key='transcription')],\n",
    "]\n",
    "\n",
    "# Create GUI window\n",
    "window = sg.Window('Meeting Transcription', layout)\n",
    "\n",
    "# Create an event to signal recording thread to stop\n",
    "stop_event = threading.Event()\n",
    "\n",
    "# Create a queue to hold audio data chunks\n",
    "audio_queue = queue.Queue()\n",
    "\n",
    "# Set an initial noise threshold\n",
    "noise_threshold = 0.01\n",
    "\n",
    "# Event loop\n",
    "recording_thread = None\n",
    "while True:\n",
    "    event, values = window.read()\n",
    "    if event == sg.WIN_CLOSED:\n",
    "        break\n",
    "    elif event == 'Start Recording':\n",
    "        # Start recording on a separate thread\n",
    "        stop_event.clear()\n",
    "        recording_thread = threading.Thread(target=record_audio, args=(audio_queue, stop_event, noise_threshold))\n",
    "        recording_thread.start()\n",
    "    elif event == 'Stop Recording':\n",
    "        # Signal the recording thread to stop\n",
    "        stop_event.set()\n",
    "        if recording_thread is not None:\n",
    "            recording_thread.join()\n",
    "        # Process remaining active chunks in the queue\n",
    "        transcriptions = []\n",
    "        while not audio_queue.empty():\n",
    "            active_chunk = audio_queue.get()\n",
    "            audio_bytes = save_wav_in_memory(active_chunk, fs)\n",
    "            # Save the audio to a temporary WAV file\n",
    "            with open(\"temp_audio.wav\", \"wb\") as f:\n",
    "                f.write(audio_bytes)\n",
    "            # Transcribe the audio using OpenAI's Whisper ASR API\n",
    "            file = open(\"temp_audio.wav\", \"rb\")\n",
    "            transcription = openai.Audio.transcribe(\"whisper-1\", file)\n",
    "            transcriptions.append(transcription['choices'][0]['text'])\n",
    "        # Update GUI with transcribed text (separated by newlines)\n",
    "        window['transcription'].update('\\n'.join(transcriptions))\n",
    "\n",
    "# Close GUI window\n",
    "window.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3076a7c-7acd-4224-a384-70801d4477d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9 (record_and_transcribe):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "Expression 'ret' failed in 'src/hostapi/alsa/pa_linux_alsa.c', line: 1736\n",
      "Expression 'AlsaOpen( &alsaApi->baseHostApiRep, params, streamDir, &self->pcm )' failed in 'src/hostapi/alsa/pa_linux_alsa.c', line: 1904\n",
      "Expression 'PaAlsaStreamComponent_Initialize( &self->capture, alsaApi, inParams, StreamDirection_In, NULL != callback )' failed in 'src/hostapi/alsa/pa_linux_alsa.c', line: 2171\n",
      "Expression 'PaAlsaStream_Initialize( stream, alsaHostApi, inputParameters, outputParameters, sampleRate, framesPerBuffer, callback, streamFlags, userData )' failed in 'src/hostapi/alsa/pa_linux_alsa.c', line: 2839\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_497790/376463701.py\", line 41, in record_and_transcribe\n",
      "  File \"/home/srudloff/.local/lib/python3.10/site-packages/sounddevice.py\", line 1421, in __init__\n",
      "    _StreamBase.__init__(self, kind='input', wrap_callback='array',\n",
      "  File \"/home/srudloff/.local/lib/python3.10/site-packages/sounddevice.py\", line 898, in __init__\n",
      "    _check(_lib.Pa_OpenStream(self._ptr, iparameters, oparameters,\n",
      "  File \"/home/srudloff/.local/lib/python3.10/site-packages/sounddevice.py\", line 2747, in _check\n",
      "    raise PortAudioError(errormsg, err)\n",
      "sounddevice.PortAudioError: Error opening InputStream: Device unavailable [PaErrorCode -9985]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Recording started. Press Enter to stop recording...\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording and transcription complete.\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import threading\n",
    "import queue\n",
    "import openai\n",
    "import keyring\n",
    "import io\n",
    "import wave\n",
    "from datetime import datetime\n",
    "\n",
    "# Define audio recording parameters\n",
    "fs = 44100  # Sample rate\n",
    "recording_duration = 5  # Duration of recording for noise baseline in seconds\n",
    "chunk_duration = 0.5  # Duration of each chunk in seconds\n",
    "chunk_samples = int(fs * chunk_duration)  # Number of samples in each chunk\n",
    "threshold_multiplier = 1.5  # Multiplier for noise threshold\n",
    "\n",
    "# Define a function to save the numpy array as a WAV file in memory\n",
    "def save_wav_in_memory(audio_data):\n",
    "    byte_io = io.BytesIO()\n",
    "    with wave.open(byte_io, 'wb') as wav_file:\n",
    "        wav_file.setnchannels(1)\n",
    "        wav_file.setsampwidth(2)\n",
    "        wav_file.setframerate(fs)\n",
    "        wav_file.writeframes(audio_data.astype(np.int16).tobytes())\n",
    "    byte_io.seek(0)\n",
    "    return byte_io.read()\n",
    "\n",
    "# Calculate root-mean-square (RMS) energy of a chunk\n",
    "def calculate_rms(chunk):\n",
    "    return np.sqrt(np.mean(np.square(chunk)))\n",
    "\n",
    "# Simple Voice Activity Detection (VAD)\n",
    "def is_voice_active(chunk, threshold):\n",
    "    return calculate_rms(chunk) > threshold\n",
    "\n",
    "# Define a function for recording audio and transcribing chunks\n",
    "def record_and_transcribe(stop_event, threshold):\n",
    "    buffer = np.array([])\n",
    "    active_chunk = np.array([])\n",
    "    with sd.InputStream(samplerate=fs) as stream:\n",
    "        while not stop_event.is_set():\n",
    "            chunk, _ = stream.read(chunk_samples)  # Read chunk from the stream\n",
    "            chunk = chunk.flatten()  # Flatten the chunk to 1 dimension\n",
    "            if is_voice_active(chunk, threshold):\n",
    "                # If active voice detected, append chunk to active_chunk\n",
    "                active_chunk = np.concatenate((active_chunk, chunk))\n",
    "            elif len(active_chunk) > 0:\n",
    "                # If pause detected, transcribe the active_chunk\n",
    "                audio_bytes = save_wav_in_memory(active_chunk)\n",
    "                # Save the audio to a temporary WAV file\n",
    "                with open(\"temp_audio.wav\", \"wb\") as f:\n",
    "                    f.write(audio_bytes)\n",
    "                # Transcribe the audio using OpenAI's Whisper ASR API\n",
    "                file = open(\"temp_audio.wav\", \"rb\")\n",
    "                transcription = openai.Audio.transcribe(\"whisper-1\", file)\n",
    "                # Print transcribed text to console\n",
    "                print(transcription['choices'][0]['text'])\n",
    "                active_chunk = np.array([])\n",
    "            # Append chunk to buffer for noise threshold calculation\n",
    "            buffer = np.concatenate((buffer, chunk))\n",
    "            if len(buffer) > fs * recording_duration:\n",
    "                # Calculate threshold based on RMS energy of recorded buffer\n",
    "                threshold = threshold_multiplier * calculate_rms(buffer)\n",
    "                buffer = np.array([])\n",
    "\n",
    "# OpenAI API key\n",
    "openai.api_key = keyring.get_password(\"system\", \"openai_key\")\n",
    "\n",
    "# Create an event to signal recording thread to stop\n",
    "stop_event = threading.Event()\n",
    "\n",
    "# Set an initial noise threshold\n",
    "noise_threshold = 0.01\n",
    "\n",
    "# Start recording and transcribing on a separate thread\n",
    "recording_thread = threading.Thread(target=record_and_transcribe, args=(stop_event, noise_threshold))\n",
    "recording_thread.start()\n",
    "\n",
    "# Prompt user to press Enter to stop recording\n",
    "input(\"Recording started. Press Enter to stop recording...\\n\")\n",
    "\n",
    "# Signal the recording thread to stop\n",
    "stop_event.set()\n",
    "recording_thread.join()\n",
    "\n",
    "\n",
    "print(\"Recording and transcription complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f1835-4045-469c-b49c-838fdc4e307e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
