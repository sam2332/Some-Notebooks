{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "7b070182-8858-47db-a887-8c6416daf792",
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import mediapipe as mp\n",
                "\n",
                "mp_drawing = mp.solutions.drawing_utils\n",
                "mp_drawing_styles = mp.solutions.drawing_styles\n",
                "mp_pose = mp.solutions.pose"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f7085737-abc4-4fe6-9e3f-7aa8065656ab",
            "metadata": {},
            "outputs": [],
            "source": [
                "# For static images:\n",
                "IMAGE_FILES = []\n",
                "BG_COLOR = (192, 192, 192)  # gray\n",
                "with mp_pose.Pose(\n",
                "    static_image_mode=True,\n",
                "    model_complexity=2,\n",
                "    enable_segmentation=True,\n",
                "    min_detection_confidence=0.5,\n",
                ") as pose:\n",
                "    for idx, file in enumerate(IMAGE_FILES):\n",
                "        image = cv2.imread(file)\n",
                "        image_height, image_width, _ = image.shape\n",
                "        # Convert the BGR image to RGB before processing.\n",
                "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
                "\n",
                "        if not results.pose_landmarks:\n",
                "            continue\n",
                "        print(\n",
                "            f\"Nose coordinates: (\"\n",
                "            f\"{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].x * image_width}, \"\n",
                "            f\"{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].y * image_height})\"\n",
                "        )\n",
                "\n",
                "        annotated_image = image.copy()\n",
                "        # Draw segmentation on the image.\n",
                "        # To improve segmentation around boundaries, consider applying a joint\n",
                "        # bilateral filter to \"results.segmentation_mask\" with \"image\".\n",
                "        condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
                "        bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
                "        bg_image[:] = BG_COLOR\n",
                "        annotated_image = np.where(condition, annotated_image, bg_image)\n",
                "        # Draw pose landmarks on the image.\n",
                "        mp_drawing.draw_landmarks(\n",
                "            annotated_image,\n",
                "            results.pose_landmarks,\n",
                "            mp_pose.POSE_CONNECTIONS,\n",
                "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style(),\n",
                "        )\n",
                "        cv2.imwrite(\"/tmp/annotated_image\" + str(idx) + \".png\", annotated_image)\n",
                "        # Plot pose world landmarks.\n",
                "        mp_drawing.plot_landmarks(\n",
                "            results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS\n",
                "        )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7befa32a-a68c-4ea3-bfb9-5a2501391e2e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# For webcam input:\n",
                "cap = cv2.VideoCapture(0)\n",
                "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
                "    while cap.isOpened():\n",
                "        success, image = cap.read()\n",
                "        if not success:\n",
                "            print(\"Ignoring empty camera frame.\")\n",
                "            # If loading a video, use 'break' instead of 'continue'.\n",
                "            continue\n",
                "\n",
                "        # To improve performance, optionally mark the image as not writeable to\n",
                "        # pass by reference.\n",
                "        image.flags.writeable = False\n",
                "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
                "        results = pose.process(image)\n",
                "\n",
                "        # Draw the pose annotation on the image.\n",
                "        image.flags.writeable = True\n",
                "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
                "        mp_drawing.draw_landmarks(\n",
                "            image,\n",
                "            results.pose_landmarks,\n",
                "            mp_pose.POSE_CONNECTIONS,\n",
                "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style(),\n",
                "        )\n",
                "        # Flip the image horizontally for a selfie-view display.\n",
                "        cv2.imshow(\"MediaPipe Pose\", cv2.flip(image, 1))\n",
                "        if cv2.waitKey(5) & 0xFF == 27:\n",
                "            break\n",
                "cap.release()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3fee8194-596c-4803-9b95-a4c1973f7382",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        },
        "scenes_data": {
            "active_scene": "Default Scene",
            "init_scene": "",
            "scenes": [
                "Default Scene"
            ]
        },
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "state": {},
                "version_major": 2,
                "version_minor": 0
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}