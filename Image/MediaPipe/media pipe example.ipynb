{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "6cf83075-6298-48bd-92b8-eeed70c1e4e9",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "60d5ac6f-d84d-482c-8768-c7efe761affd",
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "import cv2\n",
                "import mediapipe as mp"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "29e643f0-d395-4ce8-bdb6-5bf4bc1afe9c",
            "metadata": {},
            "outputs": [],
            "source": [
                "samples = Path(\"../Samples\")\n",
                "mp_drawing = mp.solutions.drawing_utils\n",
                "mp_face_mesh = mp.solutions.face_mesh\n",
                "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "800fcfe0-9651-4f71-916f-22fd9f7a927f",
            "metadata": {},
            "outputs": [],
            "source": [
                "with mp_face_mesh.FaceMesh(\n",
                "    static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5\n",
                ") as face_mesh:\n",
                "    for idx, file in enumerate(samples.iterdir()):\n",
                "        image = cv2.imread(str(file))\n",
                "        # Convert the BGR image to RGB before processing.\n",
                "        results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
                "\n",
                "        # Print and draw face mesh landmarks on the image.\n",
                "        if not results.multi_face_landmarks:\n",
                "            continue\n",
                "        annotated_image = image.copy()\n",
                "        for face_landmarks in results.multi_face_landmarks:\n",
                "            print(\"face_landmarks:\", face_landmarks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "54f5a55e-46f3-42b5-8970-56b8b65cf98f",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        },
        "scenes_data": {
            "active_scene": "Default Scene",
            "init_scene": "",
            "scenes": [
                "Default Scene"
            ]
        },
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "state": {},
                "version_major": 2,
                "version_minor": 0
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}